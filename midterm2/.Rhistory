library("tidyverse")
library("janitor")
library("naniar")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>% clean_names()
sharks_test <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>% clean_names()
summary(sharks)
miss_var_summary(sharks)
sharks <- sharks %>%
filter(incident_num != "NOT COUNTED")
sharks_test %>%
filter(!incident_num=="NOT COUNTED")
sharks %>%
group_by(county) %>%
summarise(n = n()) %>%
ggplot(aes(x=reorder(county, n), y=n)) +
geom_col(fill = "#0099f9", alpha=0.8)+
labs(title="Shark Incidents by County (1950-2022)",
x=NULL,
y="n") +
theme(axis.text.x = element_text(angle = 60, hjust = 1),
plot.title = element_text(size = 14, face="bold"))+
geom_text(aes(label = n), vjust = -0.2, size = 3, color = "black")
sharks %>%
count(county) %>%
arrange(desc(n))
sharks %>%
group_by(month) %>%
summarise(total=n(), .groups='keep') %>%
ggplot(aes(x=as_factor(month), y=total))+
geom_col(fill = "#0099f9", alpha=0.8)+
labs(title="Shark Incidents by Month",
x="Month",
y="n")+
theme(plot.title = element_text(size = 14, face="bold"))
sharks %>%
tabyl(county, injury) %>%
adorn_totals("col") %>%
arrange(desc(fatal)) %>%
as_tibble()
sharks %>%
group_by(county, injury) %>%
summarise(total=n(), .groups='keep') %>%
pivot_wider(names_from = injury, values_from = total) %>%
mutate(total=sum(minor, major, fatal, none, na.rm=T)) %>%
arrange(desc(fatal))
sharks %>%
count(mode) %>%
arrange(desc(n))
sharks %>%
ggplot(aes(x=injury, fill=injury))+
geom_bar(alpha=0.8, position="dodge")+
facet_wrap(~mode)+
labs(title="Injury Type by Activity",
x=NULL,
y="Number of Incidents")+
theme(strip.text = element_text(size=10),
axis.text.x = element_text(size=8, angle = 60, hjust = 1))
sharks %>%
count(species) %>%
arrange(desc(n))
sharks %>%
filter(species=="White") %>%
ggplot(aes(x=injury))+
geom_bar(fill = "#0099f9", alpha=0.8)+
labs(title="Incidents Involving Great White Sharks",
x="Injury",
y="n")+
theme(axis.text.x = element_text(angle = 60, hjust = 1),
plot.title = element_text(size = 14, face="bold"))
white_sharks <- read_csv("data/White sharks tracked from Southeast Farallon Island, CA, USA, 1999 2004.csv", na = c("?", "n/a")) %>% clean_names()
glimpse(white_sharks)
miss_var_summary(white_sharks)
white_sharks %>%
filter(sex!="NA") %>%
group_by(sex) %>%
summarise(mean_length=mean(total_length_cm, na.rm=T),
n=n(), .groups='keep')
white_sharks %>%
filter(sex!="NA") %>%
ggplot(aes(x=sex, y=total_length_cm, fill=sex))+
geom_boxplot(alpha=0.8)+
labs(title="Length of Great White Sharks by Sex",
x="Sex",
y="Total Length (cm)")
white_sharks %>%
filter(sex!="NA") %>%
ggplot(aes(x=total_length_cm))+
geom_density(fill = "#0099f9", alpha=0.8)+
facet_wrap(~sex)+
labs(title="Distribution of Total Length by Sex",
x="Total Length (cm)",
y=NULL)+
theme(strip.text = element_text(size=10),
axis.text.x = element_text(size=8, angle = 60, hjust = 1))
knitr::opts_chunk$set(echo = TRUE)
clownfish <- read_csv("clownfish_log.csv")%>% clean_names()
View(clownfish)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library("tidyverse")
library("janitor")
library("lubridate") #this will help us manage dates
files <- list.files(path = "data/spiders", pattern = ".csv", full.names = TRUE)
files
spider_list <- lapply(files, read_csv)
spider_list[[3]]
names(spider_list)
str(spider_list)
names(spider_list[[1]])
glimpse([[1]])
glimpse(spider_list[[1]])
names <- list.files(path = "data/spiders", pattern = ".csv")
names
names_list <- strsplit(names, split = " .csv")
names_list
names_vec <- unlist(names_list)
names_vec
names(spider_list) <- names_vec
names(spider_list)
butte <- spider_list[["Butte"]]
spider_list[["Butte"]]
spiders_all <- bind_rows(spider_list)
spiders_all
table_A <- read_csv("data/table_A.csv")
table_B <- read_csv("data/table_B.csv")
table_A
table_B
inner_exampleDF <- inner_join(table_A, table_B, by="customer_ID") #customer_ID is the unique handle
inner_exampleDF
left_exampleDF <- left_join(table_A, table_B, by="customer_ID")
left_exampleDF
right_exampleDF <- right_join(table_A, table_B, by="customer_ID")
right_exampleDF
anti_exampleDF <- anti_join(table_A, table_B, by="customer_ID")
anti_exampleDF
full_exampleDF <- full_join(table_A, table_B, by="customer_ID")
full_exampleDF
anti_exampleDF <- anti_join(table_A, table_B, by="customer_ID")
anti_exampleDF
spiders_locs <- read_csv("data/spiders locations/spiders_locations.csv")
spiders_locs <- read_csv("data/spiders locations/spiders_locations.csv")
spiders_locs
spiders_with_locs <- left_join(spiders_all, spiders_locs, by="Accession")
summary(spiders_with_locs)
#add spiders_loc to spiders_all
day <- today()
day
str(day)
datetime <- now()
datetime
dateformat1 <- "20200922"
dateformat2 <- "09-22-2020"
dateformat3 <- "22/09/2020"
dateformat4 <- "09-22-2020 17:00:00"
dateformat5 <- "20200922 170000"
ymd(dateformat1)
mdy(dateformat2)
dmy(dateformat3)
mdy_hms(dateformat4)
ymd_hms(dateformat5)
write.csv(spiders_with_locs, file = "spiders_with_locs.csv", row.names = FALSE)
library(tidyverse)
library(janitor)
#install.packages("ggmap")
library(ggmap)
register_stadiamaps("e77f55a8-a371-44cd-a7dd-6384b4586d64", write = FALSE)
spiders <- read_csv("data/spiders_with_locs.csv")%>% clean_names()
spiders <- spiders %>% filter(latitude<=42)
spiders <- spiders %>% filter(latitude<=42)
spiders %>%
select(latitude, longitude) %>%
summary()
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03) #f is the fraction of the bounding box to add to the range
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03) #f is the fraction of the bounding box to add to the range
map1 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7) #zoom is also very sensitive
ggmap(map1)
ggmap(map1) +
geom_point(data = spiders, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Spider Locations")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>%
clean_names() %>%
filter(longitude !="NA" & latitude !="NA") %>% # pulling out NA locations
mutate(longitude = as.numeric(longitude)) # converting longitude to numeric
sharks_dups <- sharks %>%
distinct(location, .keep_all = TRUE) # remove duplicate locations, but keep the remaining variables
View(sharks_dups)
sharks_dups %>%
select(latitude, longitude) %>%
summary()
lat <- c(32.59, 41.56) #min, max
long <- c(-124.7, -117.1)
bbox <- make_bbox(long, lat, f = 0.03)
map1_shark <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map1_shark)
sharks_dups %>%
select(longitude, latitude) %>%
summary()
lat2 <- c(32.59, 41.56) #min, max
long2 <- c(-124.7, -117.1)
bbox2 <- make_bbox(long, lat, f = 0.03)
library(tidyverse)
library(janitor)
#install.packages("ggmap")
library(ggmap)
register_stadiamaps("e77f55a8-a371-44cd-a7dd-6384b4586d64", write = FALSE)
spiders <- read_csv("data/spiders_with_locs.csv")%>% clean_names()
spiders <- spiders %>% filter(latitude<=42)
spiders %>%
select(latitude, longitude) %>%
summary()
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03) #f is the fraction of the bounding box to add to the range
map1 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7) #zoom is also very sensitivee
ggmap(map1)
ggmap(map1) +
geom_point(data = spiders, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Spider Locations")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>%
clean_names() %>%
filter(longitude !="NA" & latitude !="NA") %>% # pulling out NA locations
mutate(longitude = as.numeric(longitude)) # converting longitude to numeric
sharks_dups <- sharks %>%
distinct(location, .keep_all = TRUE) # remove duplicate locations, but keep the remaining variables
sharks_dups %>%
select(longitude, latitude) %>%
summary()
lat2 <- c(32.59, 41.56) #min, max
long2 <- c(-124.7, -117.1)
bbox2 <- make_bbox(long2, lat2, f = 0.03)
map2 <- get_stadiamap(bbox2, maptype = "stamen_terrain", zoom=7)
ggmap(map2)
ggmap(map2)+
geom_point(data = sharks_dups, aes(x=longitude, y=latitude), size=0.8)+
labs(x="Longitude", y="Latitude", title = "Shark Attacks Coastal California, 1950-2022")
sharks_fatal %>%
select(longitude, latitude) %>%
summary()
sharks_fatal <- sharks_dups %>%
filter(injury=="fatal")
sharks_fatal
sharks_fatal %>%
select(longitude, latitude) %>%
summary()
lat3 <-  c(-123.8, -117.3)
long3 <- c(32.85, 39.58)
bbox3 <- make_bbox(long3, lat3, f=0.3)
ggmap(map3)+
geom_point(data = sharks_fatal, aes(x=longitude, y=latitude), size=0.8)+
labs(x="Longitude", y="Latitude", title = "Shark Fatalities Coastal California, 1950-2022")
lat3 <-  c(-123.8, -117.3)
long3 <- c(32.85, 39.58)
bbox3 <- make_bbox(long3, lat3, f=0.3)
map3 <- get_stadiamap(bbox3, maptype = "stamen_terrain", zoom=7)
lat3 <-  c(-123.8, -117.3)
long3 <- c(32.85, 39.58)
bbox3 <- make_bbox(long3, lat3, f=0.3)
map3 <- get_stadiamap(bbox3, maptype = "stamen_terrain", zoom=7)
sharks_fatal %>%
select(longitude, latitude) %>%
summary()
lat3 <-  c(-123.8, -117.3)
long3 <- c(32.85, 39.58)
bbox3 <- make_bbox(long3, lat3, f=0.3)
map3 <- get_stadiamap(bbox3, maptype = "stamen_terrain", zoom=7)
ggmap(map3)+
geom_point(data = sharks_fatal, aes(x=longitude, y=latitude), size=0.8)+
labs(x="Longitude", y="Latitude", title = "Shark Fatalities Coastal California, 1950-2022")
ggmap(map2)+
geom_point(data = sharks_dups, aes(x=longitude, y=latitude, color=injury), size=0.8)+
labs(x="Longitude", y="Latitude", title = "Shark Attacks Coastal California, 1950-2022")
